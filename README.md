# Natural Language Processing (NLP)

Natural Language Processing (NLP) is a field of study focused on enabling computers to analyze, understand, and derive meaningful information from textual data in a smart and efficient manner.

---

## Key Concepts in NLP

### Tokenization

Tokenization is the process of converting a text into smaller units called tokens.

- **Tokens:** Words or entities present in the text.
- **Text Object:** A sentence, phrase, word, or an article.

---

## Text Preprocessing

Text is the most unstructured form of all avaliable data, variaous type of noises are present in it. The entire process of cleaning and standardization of text, making it noise-free and ready for analysis is known as text preprocessing.

### It is predominantly comprised of three steps:

- **Noise Removal**
- **Lexicon Normalization**
- **Object Standardization**
